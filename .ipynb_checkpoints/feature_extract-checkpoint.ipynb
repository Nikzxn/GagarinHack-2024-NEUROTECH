{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:49:55.438220Z",
     "start_time": "2024-04-12T11:49:55.435845Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "video_path = \"../Train/anomaly/3.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee37909e87129f74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:49:55.754604Z",
     "start_time": "2024-04-12T11:49:55.752471Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def extract_lighting_change(frame1, frame2):\n",
    "    ksize = (10, 10) \n",
    "    f1_blur = cv2.blur(frame1, ksize)  \n",
    "    f2_blur=cv2.blur(frame2,ksize)\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    return np.mean(diff)\n",
    "\n",
    "def extract_blur(frame):\n",
    "    #фильтр обнаружения краев, если дисперсии мало - есть размытие\n",
    "    blur = cv2.Laplacian(frame, cv2.CV_64F).var()\n",
    "    return blur\n",
    "\n",
    "def extract_camera_angle_change(frame1, frame2):\n",
    "    sift = cv2.SIFT_create()\n",
    "    ksize = (10, 10) \n",
    "    f1_blur = cv2.blur(frame1, ksize)  \n",
    "    f2_blur=cv2.blur(frame2,ksize)\n",
    "    # SIFT определяет ключевые точки и их дескрипторы\n",
    "    kp1, des1 = sift.detectAndCompute(f1_blur, None)\n",
    "    kp2, des2 = sift.detectAndCompute(f2_blur, None)\n",
    "\n",
    "    # проходимся knn матчером по соответствующим точкам обоих кадров\n",
    "    # если \"хороших\" совпадений мало - камеру сдвинули\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    return len(good_matches)\n",
    "\n",
    "def extract_features_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    prev_frame = None\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"End of video\")\n",
    "            break\n",
    "        \n",
    "        if prev_frame is not None:\n",
    "            lighting_change = extract_lighting_change(prev_frame, frame)\n",
    "            blur = extract_blur(frame)\n",
    "            camera_angle_change = extract_camera_angle_change(prev_frame, frame)\n",
    "            cv2.setWindowTitle(\"frame\",f\"lg:{round(lighting_change,2)} blur:{blur} cac:{camera_angle_change}\")\n",
    "            \n",
    "        \n",
    "        prev_frame = frame\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a87b2c28c55db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:50:39.312119Z",
     "start_time": "2024-04-12T11:49:56.423227Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extract_features_from_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47e7512dce10bf22",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocess_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return\n",
    "    \n",
    "    prev_frame = None\n",
    "    features_array=[]\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"End of video\")\n",
    "            break\n",
    "        \n",
    "        if prev_frame is not None:\n",
    "            lighting_change = extract_lighting_change(prev_frame, frame)\n",
    "            blur = extract_blur(frame)\n",
    "            camera_angle_change = extract_camera_angle_change(prev_frame, frame)\n",
    "            \n",
    "            # print(\"Lighting Change:\", lighting_change)\n",
    "            # print(\"Blur:\", blur)\n",
    "            # print(\"Camera Angle Change:\", camera_angle_change)\n",
    "            features_array.append([blur,lighting_change,camera_angle_change])\n",
    "            \n",
    "        \n",
    "        prev_frame = frame\n",
    "    return pd.DataFrame(data=features_array,columns=[\"Blur\",\"Lighting Change\",\"Camera Angle Change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efad3584-8bfc-4e88-8e39-c48f0c58321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=preprocess_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab9aa04-8f98-4bf7-b326-c11e170ac1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blur</th>\n",
       "      <th>Lighting Change</th>\n",
       "      <th>Camera Angle Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323.95767</td>\n",
       "      <td>0.221717</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Blur  Lighting Change  Camera Angle Change\n",
       "0  323.95767         0.221717                 1900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae89ed5e-8f43-422b-9749-6fdecea698b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Train\\\\anomaly\\\\0.mp4',\n",
       " '../Train\\\\anomaly\\\\2.mp4',\n",
       " '../Train\\\\anomaly\\\\3.mp4',\n",
       " '../Train\\\\anomaly\\\\4.mp4',\n",
       " '../Train\\\\anomaly\\\\5.mp4',\n",
       " '../Train\\\\not_anomaly\\\\0.mp4',\n",
       " '../Train\\\\not_anomaly\\\\1.mp4',\n",
       " '../Train\\\\not_anomaly\\\\2.mp4',\n",
       " '../Train\\\\not_anomaly\\\\3.mp4',\n",
       " '../Train\\\\not_anomaly\\\\4.mp4',\n",
       " '../Train\\\\not_anomaly\\\\5.mp4',\n",
       " '../Train\\\\not_anomaly\\\\6.mp4',\n",
       " '../Train\\\\not_anomaly\\\\7.mp4',\n",
       " '../Train\\\\not_anomaly\\\\8.mp4']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "train_path=\"../Train/*/*.mp4\"\n",
    "files=glob.glob(train_path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b88caf0c-d84d-4d31-920d-c268e8fd6695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.mp4 anomaly\n",
      "2.mp4 anomaly\n",
      "3.mp4 anomaly\n",
      "4.mp4 anomaly\n",
      "5.mp4 anomaly\n",
      "0.mp4 not_anomaly\n",
      "1.mp4 not_anomaly\n",
      "2.mp4 not_anomaly\n",
      "3.mp4 not_anomaly\n",
      "4.mp4 not_anomaly\n",
      "5.mp4 not_anomaly\n",
      "6.mp4 not_anomaly\n",
      "7.mp4 not_anomaly\n",
      "8.mp4 not_anomaly\n"
     ]
    }
   ],
   "source": [
    "for pth in files:\n",
    "    df=preprocess_video(pth)\n",
    "    tag=pth.split(\"\\\\\")[-2]\n",
    "    name=pth.split(\"\\\\\")[-1]\n",
    "    print(name,tag)\n",
    "    df.to_csv(f\"../csv/{tag}/{name[0]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f7f3f-2e41-423a-8e82-f11ac919e0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
