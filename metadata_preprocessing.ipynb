{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-13T16:38:41.446315Z",
     "start_time": "2024-04-13T16:38:41.431610Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "files = [\"/Users/elhidze/Gagarin/metadata/train/normal/0.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/1.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/2.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/3.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/4.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/5.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/6.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/7.json\",\n",
    "        \"/Users/elhidze/Gagarin/metadata/train/normal/8.json\"]\n",
    "outs = ['/Users/elhidze/Gagarin/meta_csv/train/normal/0.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/1.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/2.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/3.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/4.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/5.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/6.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/7.csv',\n",
    "        '/Users/elhidze/Gagarin/meta_csv/train/normal/8.csv']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T16:38:41.573283Z",
     "start_time": "2024-04-13T16:38:41.568698Z"
    }
   },
   "id": "e6050882d953c4b6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    with open(files[i]) as f:\n",
    "        frames = json.load(f)\n",
    "    \n",
    "    frames_json = json.dumps(frames)\n",
    "    frames = json.loads(frames_json)\n",
    "    \n",
    "    pkt_pos = [int(frame['pkt_pos']) for frame in frames]\n",
    "    byte_pos = pkt_pos\n",
    "    time_pos = [i / 25 for i in range(len(pkt_pos))]\n",
    "    pkt_sizes = [int(frame['pkt_size']) for frame in frames]\n",
    "    m = max(pkt_sizes)\n",
    "    pkt_sizes = [size / m for size in pkt_sizes]\n",
    "    pic_types = [frame['pict_type'] for frame in frames]\n",
    "    \n",
    "    df = pd.DataFrame({'time_pos': time_pos, 'byte_pos': byte_pos, 'size': pkt_sizes, 'type': pic_types}).sort_values(by='time_pos')\n",
    "    df.to_csv(outs[i], index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T16:38:43.423447Z",
     "start_time": "2024-04-13T16:38:42.060867Z"
    }
   },
   "id": "36e1cb3e7befbcee"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "anomaly_data = {\n",
    "    '0': {\n",
    "        'move': [(48, 52), (93, 98), (140, 142), (180, 185), (248, 249), (313, 315), (413, 414), (471, 474), (521, 522), (615, 619), (670, 674)]\n",
    "    },\n",
    "    '2': {\n",
    "        'blur': [(19, 42), (81, 97), (100, 127), (186, 216), (301, 303), (372, 409), (525, 556), (828, 878), (983, 985), (1014, 1017), (1085, 1087), (1153, 1166)],\n",
    "        'move': [(141, 142), (240, 247), (751, 756), (758, 762), (919, 924), (983, 985), (1014, 1017), (1085, 1087), (1141, 1142)]\n",
    "    },\n",
    "    '3': {\n",
    "        'blur': [(19, 59), (79, 138)],\n",
    "        'move': [(0, 19), (40, 60), (80, 106), (121, 141)]\n",
    "    },\n",
    "    '4': {\n",
    "        'block': [(17, 28), (55, 64), (174, 185)],\n",
    "        'overexposure': [(28, 30), (64, 70)],\n",
    "        'blur': [(83, 153)]\n",
    "    },\n",
    "    '5': {\n",
    "        'block': [(662, 675), (679, 690)],\n",
    "        'move': [(3, 4), (324, 325), (454, 455), (507, 508), (508, 560), (547, 662), (714, 718)],\n",
    "        'blur': [(161, 221)]\n",
    "    }\n",
    "}\n",
    "\n",
    "count = 0\n",
    "for table in outs:\n",
    "    df = pd.read_csv(table)\n",
    "    \n",
    "    df['normal'] = 1\n",
    "    df['has_blur'] = 0\n",
    "    df['has_move'] = 0\n",
    "    df['has_overexposure'] = 0\n",
    "    df['has_block'] = 0\n",
    "    \n",
    "    # for anomaly_type, time_ranges in anomaly_data[str(count)].items():\n",
    "    #     for start, end in time_ranges:\n",
    "    #         df.loc[(df['time_pos'] >= start) & (df['time_pos'] <= end), f'has_{anomaly_type}'] = 1\n",
    "    # \n",
    "    # df.loc[(df['has_blur'] == 0) & (df['has_move'] == 0) & (df['has_overexposure'] == 0) & (df['has_block'] == 0), 'normal'] = 1\n",
    "    # df.loc[(df['has_blur'] == 1) | (df['has_move'] == 1) | (df['has_overexposure'] == 1) | (df['has_block'] == 1), 'normal'] = 0\n",
    "    # \n",
    "    df.to_csv(table, index=False)\n",
    "    \n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T16:38:51.358281Z",
     "start_time": "2024-04-13T16:38:51.130469Z"
    }
   },
   "id": "11c0586ffb58b8ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7b48f7684df43499"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
